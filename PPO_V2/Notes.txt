" HERE WE GOOOOO "

PATH FIXING -->
1. Fix Path for Foxtrot -> Done {1/21/2025}
2. Add random location spawing for CCA's to train -> Done {1/19/2025}
3. Add random location spawing for Foxtrot to train -> Done {1/19/2025}
4. Add cirriculum based learning for model with various basic scenarios -> Done {1/21/2025}

PATROL & PROTECT OBJECTIVE -->
1. Start with basic third object tracking & interception -> Done {1/24/2025}

TERRAIN ON Z AXIS + OBJECT TRACKING -->
1. Start with basic terrain with random spawn (CCA + stationary Foxtrot) & interception -> Done {1/25/2025} ??

SINGLE CCA ADVERSARY SWITCHING -->
1. CCA protects Foxtrot but intercepts adversarial targets that enter its proection zone (missiles)



" One Day "

EXPANSION TO MULTIDISCRETE -->
1. Ensure that when expanding CCA's - we have correct input shaping -> see o1 suggestion
2. Ensure that when expanding CCA's - Move to MultiDiscrete



LINKEDIN POST ->

Over the past few weeks, Iâ€™ve been diving deep into the world of Reinforcement Learning (RL) to expand my technical skills and challenge myself with new concepts. ğŸš€

To make this learning journey hands-on and impactful, I developed my own custom simulationâ€”a dynamic environment where an agent must track and intercept moving targets while navigating complex terrains. Along the way, I implemented techniques like reward shaping, curriculum learning, and transformer-based feature extraction to improve the modelâ€™s performance and robustness. ğŸ¯

This project has been an exciting blend of problem-solving, creativity, and resilience. Below, Iâ€™m sharing some of the lessons Iâ€™ve learned, which I hope can inspire and guide others on similar journeys. ğŸ¤–ğŸ“š

â³ Patience is Critical â³
    Itâ€™s important to allow the model sufficient time to train and stabilize. Making too many changes during the training process can introduce excessive variables, making debugging significantly harder.
ğŸ§  Foundation First ğŸ§ 
    Understanding the core concepts and logical flow is essential. This knowledge serves as the foundation for debugging and for grasping the nuances of how these systems operate.
ğŸš€ Start Simple, Scale Smartly ğŸš€
    Begin with small, manageable setups, but always design infrastructure with scalability in mind. This approach ensures your work remains adaptable as complexity grows.
ğŸ” Problem-Solving Through Isolation ğŸ”
    When the path forward isnâ€™t clear, break problems into smaller, isolated components. This makes it easier to identify issues and focus on resolving them systematically.
ğŸ¤ Collaboration is Key ğŸ¤
    When youâ€™re stuck, seeking help or a fresh perspective can often make a big difference. A second set of eyes never hurts and can lead to valuable insights.
ğŸŒŸ Failures Are Stepping Stones ğŸŒŸ
    Understanding why something doesnâ€™t work can be just as enlightening as understanding why it does. Failures provide critical insights that drive growth and improvement.
ğŸ’¡ Innovate Boldly ğŸ’¡
    If the solution isnâ€™t obvious, donâ€™t hesitate to experiment with your own strategies. Innovation often stems from challenging the norm and trying something new.
ğŸ‰ Enjoy the Process ğŸ‰
    Amidst the challenges, itâ€™s important to remember to have fun. The journey of learning and problem-solving is as rewarding as the outcome itself.

Iâ€™m excited to continue expanding the complexity of this project and exploring practical applications of reinforcement learning in real-world environments. The potential of AI and ML never ceases to amaze me, and I look forward to contributing to this incredible field. ğŸš€ğŸŒŸ